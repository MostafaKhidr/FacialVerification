{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d462238-f54a-437c-84ec-bd246908d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requered libraries\n",
    "\n",
    "import os\n",
    "import random\n",
    "import uuid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef259a1-3eb5-44b1-a354-71f23e860c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb1ce5d-e0ce-49d7-acb9-6ee7c8818807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 21:06:36.014775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 21:06:36.047599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 21:06:36.047770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# set up Gpu\n",
    "\n",
    "# avoid dom errors by seting gpu memory consumption Growth\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a459993-5e77-4b56-8db9-2a821d60b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data dir for training\n",
    "work_dir =\"/home/mostafa/Documents/Projects/FacialVerification\"\n",
    "DATA_DIR = \"data\"\n",
    "POS_DIR = os.path.join(DATA_DIR,'positive') \n",
    "NEG_DIR = os.path.join(DATA_DIR,'negative')\n",
    "ANK_DIR = os.path.join(DATA_DIR,'anchor')\n",
    "!mkdir data/positive\n",
    "!mkdir data/negative\n",
    "!mkdir data/anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b04333-b471-4e70-8a44-caaa5f4de08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the Labeled Faces in the Wild data for negative labels form http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
    "# unzip files\n",
    "!tar -xf lfw.tgz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ef4cc-7893-4996-a7b6-aa486b380688",
   "metadata": {},
   "source": [
    "## collecting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b62391-786f-4f50-b508-22bff0863bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting negative data from labeled faces data and copy it to negative data dir\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join(work_dir,'lfw',directory)):\n",
    "        current_path = os.path.join(work_dir,'lfw',directory,file)\n",
    "        destination_path = os.path.join(work_dir,NEG_DIR,file)\n",
    "        os.replace(current_path,destination_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364ae6b-3970-4112-b0ea-569b0b628547",
   "metadata": {},
   "source": [
    "#### collecting data from web cam for positive and anchor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e30ea4b-12b5-4cca-a66e-397b2fd2ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish aconnection to webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    # reading frame\n",
    "    ret, frame = cap.read()\n",
    "    # cut frame to 250X250px\n",
    "    frame=frame[120:120+250,200:200+250,:]\n",
    "    # show the captured image\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "        img_path = os.path.join(ANK_DIR,f\"{uuid.uuid1()}.jpg\")\n",
    "        cv2.imwrite(img_path,frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "        img_path = os.path.join(POS_DIR,f\"{uuid.uuid1()}.jpg\") \n",
    "        cv2.imwrite(img_path,frame)\n",
    "    cv2.imshow(\"Collected Image\",frame)\n",
    "    \n",
    "    #breaking the system when done\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# release the webcam\n",
    "cap.release()\n",
    "# colse all image show\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d1a57-74ce-48fc-83d5-565cb92af51a",
   "metadata": {},
   "source": [
    "### Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad2df5f-be8d-4127-bfb5-ce9e0d1140a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img):\n",
    "    data = []\n",
    "    for i in range(9):\n",
    "        img = tf.image.stateless_random_brightness(img,max_delta=.02,seed=(np.random.randint(10),np.random.randint(10)))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=.8, upper=1,seed=(np.random.randint(10),np.random.randint(10)))\n",
    "        img = tf.image.stateless_random_crop(img, size=(20,20,3),seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_flip_left_right(img,seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img,min_jpeg_quality=85, max_jpeg_quality=100,seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img,lower=.9, upper=1,seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        \n",
    "        data.append(img)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f27a0b4-201c-4d21-b284-1dd3e7e694c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 10:27:49.971096: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-28 10:27:49.971694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:27:49.971916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:27:49.972069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:27:50.401637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:27:50.401806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:27:50.401934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:27:50.402037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7023 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "img_path = os.listdir(ANK_DIR)[11]\n",
    "img = cv2.imread(os.path.join(ANK_DIR,img_path))\n",
    "data = data_aug(img)\n",
    "for image in data:\n",
    "    cv2.imwrite(os.path.join(ANK_DIR,f\"{uuid.uuid1()}.jpg\"), image.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb00930-9b73-4ac1-a570-96c97a098a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 21:09:05.519703: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-29 21:09:05.523830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 21:09:05.524145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 21:09:05.524382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 21:09:10.237204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 21:09:10.237395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 21:09:10.237526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 21:09:10.243485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7049 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# do augmantation to images and save it to it's dir\n",
    "i=0\n",
    "for img_path in os.listdir(POS_DIR):\n",
    "    img = cv2.imread(os.path.join(POS_DIR,img_path))\n",
    "    data = data_aug(img)\n",
    "    for image in data:\n",
    "        cv2.imwrite(os.path.join(POS_DIR,f\"{uuid.uuid1()}.jpg\"), image.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3a7ce-3b3f-4ea1-a65b-071bee972195",
   "metadata": {},
   "source": [
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe6582e-0169-4793-a45b-e394ce7772df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 10:29:55.867649: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-28 10:29:55.869722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:29:55.870356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:29:55.870824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:29:56.314006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:29:56.314191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:29:56.314318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-28 10:29:56.314438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7059 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "#data directories\n",
    "anchor = tf.data.Dataset.list_files(ANK_DIR+'/*.jpg').take(4000)\n",
    "positive = tf.data.Dataset.list_files(POS_DIR+'/*.jpg').take(4000)\n",
    "negative = tf.data.Dataset.list_files(NEG_DIR+'/*.jpg').take(4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1d367-4005-4239-aa9e-031cb3eace64",
   "metadata": {},
   "source": [
    "### image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f54e6b-254a-45d8-aa4d-a6250d1a119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(img)\n",
    "    img = tf.image.resize(img,(100,100))\n",
    "    img = img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200db66f-d524-473a-887c-0c668886d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negative = tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positive.concatenate(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ec432e-8794-4322-a0e3-866bff4c4d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'data/anchor/a2c37b7a-93f4-11ec-883e-9cb6d067c58d.jpg',\n",
       " b'data/positive/699b6d1e-9870-11ec-b06a-9cb6d067c58d.jpg',\n",
       " 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4281df28-1da3-45ab-85a5-44bf2621c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img,validation_img,label):\n",
    "    return (preprocess(input_img),preprocess(validation_img),label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ca26b9-bcc1-48c0-bdcf-52b06cc603ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img,validation_img,label=preprocess_twin(*(data.as_numpy_iterator().next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc5e1d4a-9cbc-40fc-a968-14f0e1d30caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "505dfc00-c2b2-4d42-945d-19ef6f5a060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a2da69-b516-4491-b7d5-c7b3204c6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf2b85-6080-448f-8786-d84e90d7d870",
   "metadata": {},
   "source": [
    "# creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d96f185b-9b3a-4d66-b450-d2f2a3fc8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(): \n",
    "    inp = Input(shape=(100,100,3),name=\"Input Image\")\n",
    "    C1 = Conv2D(64,(10,10),activation='relu')(inp)\n",
    "    M1 = MaxPooling2D(64,(2,2),padding='same')(C1)\n",
    "    \n",
    "    C2 = Conv2D(128,(7,7),activation='relu')(M1)\n",
    "    M2 = MaxPooling2D(64,(2,2),padding='same')(C2)\n",
    "    \n",
    "    C3 = Conv2D(128,(4,4),activation='relu')(M2)\n",
    "    M3 = MaxPooling2D(64,(2,2),padding='same')(C3)\n",
    "    \n",
    "    C4 = Conv2D(256,(4,4),activation='relu')(M3)\n",
    "    F1 = Flatten()(C4)\n",
    "    FC1 = Dense(units=4069,activation='sigmoid')(F1)\n",
    "\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[FC1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dcf7fd7-8a94-4496-9899-acc9b0062d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bdaae83-b52f-4c14-84f1-48a4dd591306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4069)              37503973  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,711,589\n",
      "Trainable params: 38,711,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef786ae-3ccb-4c61-a965-45b23c5145d3",
   "metadata": {},
   "source": [
    "### Build Distance Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22ceb2b2-487c-4511-aa38-cf2379014cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1DIST(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__()\n",
    "    \n",
    "    def call(self,input_img,validation_img):\n",
    "        return tf.math.abs(input_img-validation_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4f1b291-0d20-4f3b-8a9c-2658c48b2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siames_model():\n",
    "    input_image = Input(shape=(100,100,3), name = \"Input Embedding\")\n",
    "    validation_image = Input(shape=(100,100,3), name = \"Validation Embedding\")\n",
    "    \n",
    "    siames_layer = L1DIST()\n",
    "    siames_layer._name =\"DistanceLayer\"\n",
    "    distances = siames_layer(model(input_image),model(validation_image))\n",
    "    \n",
    "    classifier = Dense(1, activation = 'sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs = [input_image, validation_image], outputs = [classifier], name = 'SiameseNetwork')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d649b22-e255-4d8a-be65-26f9f72bfe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siames_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af206494-8698-4d86-97a4-ee87c7bddde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input Embedding (InputLayer)   [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Validation Embedding (InputLay  [(None, 100, 100, 3  0          []                               \n",
      " er)                            )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4069)         38711589    ['Input Embedding[0][0]',        \n",
      "                                                                  'Validation Embedding[0][0]']   \n",
      "                                                                                                  \n",
      " DistanceLayer (L1DIST)         (None, 4069)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            4070        ['DistanceLayer[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,715,659\n",
      "Trainable params: 38,715,659\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693e4d2-c5cb-4925-a1e9-5243f781df66",
   "metadata": {},
   "source": [
    "## Training Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7db1b-555f-407b-8682-31ac566fa1d1",
   "metadata": {},
   "source": [
    "### Loss Function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e29dcea-1473-49f7-ba93-be85f541d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "optimizer = tf.optimizers.Adam(1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b823e-ee20-4723-86e0-2200bc69e2f9",
   "metadata": {},
   "source": [
    "### Establish checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d71735e-aca4-42ef-91c3-1e4cf18d268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘training_checkpoints’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir training_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fea82d11-df93-4b50-8d50-753c9c9bf4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=optimizer, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e09bcd4c-8284-4f84-9e70-9e127506f6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.as_numpy_iterator().next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c87b54a4-a9f9-43b8-80dc-58b1b80b3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        #splet labels and data\n",
    "        X = batch[:2]\n",
    "        \n",
    "        y = batch[2]\n",
    "        \n",
    "        #forward_propagation \n",
    "        \n",
    "        yhat = siamese_model(X,training = True)\n",
    "        loss = binary_cross_loss(y,yhat)\n",
    "    \n",
    "    #calculating Gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "479cd4f3-6f76-4a45-9177-829da28ec58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data,epochs):\n",
    "    for epoch in range(1,epochs+1):\n",
    "        \n",
    "        print(f\"\\nEpochs {epoch}/{epochs}\")\n",
    "        progpar = tf.keras.utils.Progbar(len(data))\n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        for idx, batch in enumerate(data):\n",
    "            loss=train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat)\n",
    "            progpar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b97b63a1-b388-4aea-990f-436285835241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 10:31:29.651156: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8301\n",
      "2022-02-28 10:31:30.028037: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 117s 330ms/step\n",
      "0.06959162 0.9534384 0.9914339\n",
      "\n",
      "Epochs 2/30\n",
      "350/350 [==============================] - 114s 326ms/step\n",
      "0.020433623 0.9978479 0.99820596\n",
      "\n",
      "Epochs 3/30\n",
      "350/350 [==============================] - 113s 324ms/step\n",
      "0.0013737845 0.99318266 0.9974775\n",
      "\n",
      "Epochs 4/30\n",
      "350/350 [==============================] - 115s 328ms/step\n",
      "0.0036669555 0.9917296 0.9956679\n",
      "\n",
      "Epochs 5/30\n",
      "350/350 [==============================] - 112s 321ms/step\n",
      "0.0050732763 0.99821556 0.9996426\n",
      "\n",
      "Epochs 6/30\n",
      "350/350 [==============================] - 113s 324ms/step\n",
      "0.050407737 0.9989354 0.99929005\n",
      "\n",
      "Epochs 7/30\n",
      "350/350 [==============================] - 114s 327ms/step\n",
      "0.15560599 0.99785024 1.0\n",
      "\n",
      "Epochs 8/30\n",
      "350/350 [==============================] - 112s 319ms/step\n",
      "0.023898352 0.9953538 0.99820787\n",
      "\n",
      "Epochs 9/30\n",
      "350/350 [==============================] - 113s 324ms/step\n",
      "0.0007756312 0.9971367 0.9989244\n",
      "\n",
      "Epochs 10/30\n",
      "350/350 [==============================] - 114s 325ms/step\n",
      "0.0002639542 0.998938 1.0\n",
      "\n",
      "Epochs 11/30\n",
      "350/350 [==============================] - 115s 328ms/step\n",
      "0.00032726195 1.0 1.0\n",
      "\n",
      "Epochs 12/30\n",
      "350/350 [==============================] - 114s 326ms/step\n",
      "0.0011192287 0.99859303 0.999296\n",
      "\n",
      "Epochs 13/30\n",
      "350/350 [==============================] - 114s 326ms/step\n",
      "8.1956915e-07 0.9996405 1.0\n",
      "\n",
      "Epochs 14/30\n",
      "350/350 [==============================] - 115s 328ms/step\n",
      "0.011181695 0.99784946 0.9992821\n",
      "\n",
      "Epochs 15/30\n",
      "350/350 [==============================] - 112s 321ms/step\n",
      "0.020431705 0.9946198 0.9953338\n",
      "\n",
      "Epochs 16/30\n",
      "350/350 [==============================] - 111s 318ms/step\n",
      "0.005225803 1.0 0.9996435\n",
      "\n",
      "Epochs 17/30\n",
      "350/350 [==============================] - 114s 327ms/step\n",
      "6.0648968e-06 0.9989263 1.0\n",
      "\n",
      "Epochs 18/30\n",
      "350/350 [==============================] - 116s 332ms/step\n",
      "0.011374378 1.0 1.0\n",
      "\n",
      "Epochs 19/30\n",
      "350/350 [==============================] - 116s 332ms/step\n",
      "0.10189913 0.99608123 0.9967914\n",
      "\n",
      "Epochs 20/30\n",
      "350/350 [==============================] - 115s 328ms/step\n",
      "2.9243834e-06 0.9978693 1.0\n",
      "\n",
      "Epochs 21/30\n",
      "350/350 [==============================] - 114s 325ms/step\n",
      "0.005597478 0.9864091 0.9892396\n",
      "\n",
      "Epochs 22/30\n",
      "350/350 [==============================] - 116s 331ms/step\n",
      "0.021954123 0.99640936 0.9978425\n",
      "\n",
      "Epochs 23/30\n",
      "350/350 [==============================] - 120s 344ms/step\n",
      "0.04159357 0.9978678 0.999644\n",
      "\n",
      "Epochs 24/30\n",
      "350/350 [==============================] - 119s 340ms/step\n",
      "0.0035329247 0.99822444 1.0\n",
      "\n",
      "Epochs 25/30\n",
      "350/350 [==============================] - 116s 332ms/step\n",
      "0.0013127818 1.0 1.0\n",
      "\n",
      "Epochs 26/30\n",
      "350/350 [==============================] - 118s 336ms/step\n",
      "0.0073327674 0.9989244 1.0\n",
      "\n",
      "Epochs 27/30\n",
      "350/350 [==============================] - 116s 331ms/step\n",
      "0.004791987 1.0 1.0\n",
      "\n",
      "Epochs 28/30\n",
      "350/350 [==============================] - 117s 334ms/step\n",
      "0.00067354355 1.0 1.0\n",
      "\n",
      "Epochs 29/30\n",
      "350/350 [==============================] - 114s 327ms/step\n",
      "0.0067210495 1.0 1.0\n",
      "\n",
      "Epochs 30/30\n",
      "350/350 [==============================] - 118s 338ms/step\n",
      "1.9789777e-05 1.0 1.0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# train and save model \n",
    "train(train_data,30)\n",
    "siamese_model.save('siamesemodelv2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ec071f0-58e2-4ed8-82e8-4e510b1079ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_validate, label = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5c7568e-2d9c-44c9-afae-96567c56db04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9925942e-07],\n",
       "       [3.9683215e-08],\n",
       "       [4.1376462e-09],\n",
       "       [9.8443907e-01],\n",
       "       [5.9407168e-15],\n",
       "       [5.0078039e-09],\n",
       "       [6.9320882e-11],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999976e-01],\n",
       "       [9.9999964e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999440e-01],\n",
       "       [7.3846428e-07],\n",
       "       [8.5329638e-10]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = siamese_model.predict([test_input, test_validate])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d745a5dc-60bf-47b8-a837-3823e83c4c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 if prediction > .5 else 0 for prediction in y_hat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3d1fc1f-fdea-40e3-93ae-7c8246614cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a0aa9cf-55dc-4e7c-aad8-630396612751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a metric object \n",
    "m = Recall()\n",
    "\n",
    "# Calculating the recall value \n",
    "m.update_state(label, y_hat)\n",
    "\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ebafff6-0754-4c87-a7ea-4c3640b16bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a metric object \n",
    "m = Precision()\n",
    "\n",
    "# Calculating the recall value \n",
    "m.update_state(label, y_hat)\n",
    "\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1041a5bb-4a9d-4c80-84cc-9a1876ffd639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "r = Recall()\n",
    "p = Precision()\n",
    "\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    yhat = siamese_model.predict([test_input, test_val])\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true,yhat) \n",
    "\n",
    "print(r.result().numpy(), p.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d710a11-2704-4293-b280-d598f5b0da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# loading Model\n",
    "model = tf.keras.models.load_model('siamesemodelv2.h5',custom_objects={'L1DIST':L1DIST, \"BinaryCrossentopy\":tf.losses.BinaryCrossentropy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4452fa73-676f-4727-9ff5-4d763f35b5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input Embedding (InputLayer)   [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Validation Embedding (InputLay  [(None, 100, 100, 3  0          []                               \n",
      " er)                            )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4069)         38711589    ['Input Embedding[0][0]',        \n",
      "                                                                  'Validation Embedding[0][0]']   \n",
      "                                                                                                  \n",
      " l1dist_1 (L1DIST)              (None, 4069)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            4070        ['l1dist_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,715,659\n",
      "Trainable params: 38,715,659\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa86bdce-ad3a-4a29-a168-761323f536b2",
   "metadata": {},
   "source": [
    "## Real time test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338c1d3-77da-4ac2-be35-5956d6ecc459",
   "metadata": {},
   "source": [
    "### create dir for application data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64ca5ffc-d0bc-4251-97f7-b4a2d8d769bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./application_data\n",
    "!mkdir ./application_data/input_image\n",
    "!mkdir ./application_data/verification_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac5bb7-628e-4606-8a9d-d28172a3435a",
   "metadata": {},
   "source": [
    "#### verification Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab5db05a-7f84-449e-b76d-c87027561983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for image in os.listdir(os.path.join('./application_data','verification_images')):\n",
    "        validation_img = preprocess(os.path.join('./application_data','verification_images',image))\n",
    "        input_img = preprocess(os.path.join('./application_data','input_image',\"input_image.jpg\"))\n",
    "        \n",
    "        # make prediction \n",
    "        result = model.predict(list(np.expand_dims([input_img,validation_img],axis=1)))\n",
    "        results.append(result)\n",
    "    detection = np.sum(np.array(results)>detection_threshold)\n",
    "    verification = detection / len(os.listdir(os.path.join('./application_data','verification_images')))\n",
    "    verified = verification > verification_threshold\n",
    "    return results, verified\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2146d97-2762-4ecc-8a2d-5850b51939a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifid = False \n",
      "\n",
      "verifid = False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# establish aconnection to webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    # reading frame\n",
    "    ret, frame = cap.read()\n",
    "    # cut frame to 250X250px\n",
    "    frame=frame[120:120+250,200:200+250,:]\n",
    "    # show the captured image\n",
    "    if cv2.waitKey(1) & 0xFF == ord('v'):\n",
    "        img_path = os.path.join('./application_data','input_image',\"input_image.jpg\")\n",
    "        cv2.imwrite(img_path,frame)\n",
    "        results, verified = verify(model, .9, .7)\n",
    "        print(f\"verifid = {verified} \\n\")\n",
    "\n",
    "        \n",
    "    cv2.imshow(\"Collected Image\",frame)\n",
    "    \n",
    "    #breaking the system when done\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# release the webcam\n",
    "cap.release()\n",
    "# colse all image show\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cba6ff-9da5-4665-bb91-bea1c78e7e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013a8db-7453-4981-8058-830bd22761ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deeplearning_tf",
   "language": "python",
   "name": "deeplearning_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
